## QEUR22_INTRO21:　Julia事例(10)～ロジスティック回帰

## ～　これは「好き嫌いがある手法」だが・・・　～


D先生 （設定65歳）： “この番組は、**「高齢者によるJulia言語入門」**でございます。現在、小さな事例を積み上げております。おっと・・・、高齢者がちゃんとイノベーションの旗振りをしないと、このように（↓）通貨がどんどん安くなっていきますよ。何度もいいますが・・・。でも、FOUNDER・・・、高齢者じゃないとダメ？”

![imageJL1-21-1](https://introJL1973.github.io/images/imageJL1-21-1.jpg)

QEU:FOUNDER （設定65歳） ： “この国は**高齢者の方が能力と元気がある**から・・・。むかし、こういう話を聞きました。昔、こんな偉そうなことを言っていたんだ。彼らは「いざという時」にはやってくれますよ。”

![imageJL1-21-2](https://introJL1973.github.io/images/imageJL1-21-2.jpg)

D先生 ： “それはそうですね。若者は平成30年、不断にぶちのめされて、すでに何もできません・・・。”

- おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
- オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」
- オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER ： “ただし、オッサンは使い古されたマントラを若い人に押し付けるのはやめてください。無駄です。もう一度言うけど、無駄です。そもそも、そんな**「一つ覚え」**のやりすぎで円が安くなったんだから・・・。さて、今回はロジスティック回帰です。コレって、名前は恰好いいんだけどね・・・。”

![imageJL1-21-3](https://introJL1973.github.io/images/imageJL1-21-3.jpg)

D先生 ： “予測精度は、そんなに上がらないですよね。基本は0 or 1の予測ですから、「中間(0.3, 0.5 etc…)」がないんです。”

QEU:FOUNDER ： “ちゃんと予測が成立するには、0群と1群のデータのバランスが取れていないといけません。我々は基本的に、製造プロセスへの適応を考えているので、そんなに不良は発生しないって・・・。・・・なにはともあれやってみましょう。プログラムをドン！まずはPythonから！！！”

```python

# Import packages
import pandas as pd
import numpy as np
data = pd.read_csv("bank-loan.csv") # dataset
data

loan = data[data["default"]>=0]
loan

# Split Database
from sklearn.model_selection import train_test_split 

X = loan.drop(['default'],axis=1) 
Y = loan['default'].astype(str)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.20, random_state=0)
Y_test

# Calculate Metrics
def err_metric(CM): 
     
    TN = CM.iloc[0,0]
    FN = CM.iloc[1,0]
    TP = CM.iloc[1,1]
    FP = CM.iloc[0,1]
    precision =(TP)/(TP+FP)
    accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
    recall_score  =(TP)/(TP+FN)
    specificity_value =(TN)/(TN + FP)
     
    False_positive_rate =(FP)/(FP+TN)
    False_negative_rate =(FN)/(FN+TP)
 
    f1_score =2*(( precision * recall_score)/( precision + recall_score))
 
    print("Precision value of the model: ",precision)
    print("Accuracy of the model: ",accuracy_model)
    print("Recall value of the model: ",recall_score)
    print("Specificity of the model: ",specificity_value)
    print("False Positive rate of the model: ",False_positive_rate)
    print("False Negative rate of the model: ",False_negative_rate)
    print("f1 score of the model: ",f1_score)
    
# LogisticRegression
from sklearn.linear_model import LogisticRegression

logit= LogisticRegression(class_weight='balanced', max_iter=300, ran-dom_state=0).fit(X_train,Y_train)
target = logit.predict(X_test)
CM_logit = pd.crosstab(Y_test,target)
err_metric(CM_logit)

# Confusion Matrix
from sklearn import metrics

cm = metrics.confusion_matrix(Y_test, target)
print(cm)

```

D先生 ： “今回のデータは**「Bank Loan」**ですか・・・。有名なところ（データベース）では、「Titanic」がありますが・・・。なぜ、これを使うんです？”

![imageJL1-21-4](https://introJL1973.github.io/images/imageJL1-21-4.jpg)

QEU:FOUNDER ： “楽だから・・・(笑)。カテゴリデータがないでしょ？あと、タイタニックに比較すれば欠損値が少ないです。事例紹介ですよ・・・、我々のは・・・。ちょっと、計算結果を紹介しましょうか。”

![imageJL1-21-5](https://introJL1973.github.io/images/imageJL1-21-5.jpg)

D先生 ： “メトリックスは比較には便利ですが、様子がわかりにくいですね。それでは、**CONFUSION_MATRIX**で表現しましょう。”

![imageJL1-21-6](https://introJL1973.github.io/images/imageJL1-21-6.jpg)

QEU:FOUNDER ： “じゃあ、つぎにJulia言語でやってみましょう。プログラムをドン！！”

```julia
# Julia logistic regression
# import necessary packages
using DataFrames
using CSV
using StatsBase
using GLM
using Lathe
using MLBase
using ScikitLearn

# ---
ENV["COLUMNS"] = 1000
df=CSV.read("bank-loan.csv", DataFrame)
first(df,5)

# ---
# To see the variables’ names:
names(df)
#9-element Vector{String}:
# "age"
# "ed"
# "employ"
# "address"
# "income"
# "debtinc"
# "creddebt"
# "othdebt"
# "default"

# ---
# [FIRST]Count classes:
countmap(df.default)
#Dict{Union{Missing, Int64}, Int64} with 3 entries:
#  0       => 517
#  missing => 150
#  1       => 183

# ---
# Check variables’ type:
eltype.(eachcol(df))

# ---
# clearning data:
dropmissing!(df)

# ---
# [SECOND] check classes again:
countmap(df.default)
#Dict{Union{Missing, Int64}, Int64} with 3 entries:
#  0       => 517
#  1       => 183

# ---
# 「テストセット」と「トレーニングセット」に分割する
using Lathe.preprocess: TrainTestSplit
df_train, df_test = TrainTestSplit(df,.8)

# ---
# Create X and Y(train, test)
Y_train = df_train[!, 9]
X_train = Matrix(df_train[!, 1:8])
Y_test  = df_test[!, 9]
X_test  = Matrix(df_test[!, 1:8])

# ---
# [First]train the Logistic Regression Model:
fm = @formula(default ~ age+ed+employ+address+income+debtinc+creddebt+othdebt)
logit = glm(fm, df_train, Binomial(), ProbitLink())
#Coefficients:
#──────────────────────────────────
#                   Coef.  Std. Error      z  Pr(>|z|)    Lower 95%    Upper 95%
#──────────────────────────────────
#(Intercept)  -0.723229    0.403316    -1.79    0.0729  -1.51371      0.0672555
#age           0.0187216   0.0115188    1.63    0.1041  -0.00385481   0.041298
#ed           -0.00137624  0.0780456   -0.02    0.9859  -0.154343     0.15159
#employ       -0.155248    0.0205893   -7.54    <1e-13  -0.195602    -0.114893
#address      -0.0584402   0.0144044   -4.06    <1e-04  -0.0866722   -0.0302081
#income       -0.00483804  0.00520436  -0.93    0.3526  -0.0150384    0.00536231
#debtinc       0.0348257   0.02004      1.74    0.0822  -0.00445197   0.0741034
#creddebt      0.417544    0.0735615    5.68    <1e-07   0.273366     0.561722
#othdebt       0.0289949   0.0526869    0.55    0.5821  -0.0742695    0.132259
#──────────────────────────────────

# ---
# [Second]train the Logistic Regression Model:
fm = @formula(default ~ age+employ+address+debtinc+creddebt)
logit = glm(fm, df_train, Binomial(), ProbitLink())
#Coefficients:
#──────────────────────────────────
#                   Coef.  Std. Error      z  Pr(>|z|)    Lower 95%    Upper 95%
#──────────────────────────────────
#(Intercept)  -0.813489    0.337392    -2.41    0.0159  -1.47477     -0.152212
#age           0.0188471   0.0115048    1.64    0.1014  -0.00370188   0.0413961
#employ       -0.15293     0.0190691   -8.02    <1e-14  -0.190305    -0.115555
#address      -0.0583294   0.0143299   -4.07    <1e-04  -0.0864155   -0.0302433
#income       -0.00286243  0.00394003  -0.73    0.4675  -0.0105847    0.00485988
#debtinc       0.0434063   0.0128506    3.38    0.0007   0.0182196    0.0685931
#creddebt      0.404753    0.068723     5.89    <1e-08   0.270058     0.539447
#──────────────────────────────────

# ---
# Try to predict testing data(prob)
using MLBase: predict 
prediction=predict(logit,df_test)

# ---
# Convert the probability score to class:
# 確率スコアをクラスに変換する
Y_pred = [if x < 0.5 0 else 1 end for x in prediction]

# ---
# データの内容を確認する
prediction_df = DataFrame(y_actual = Y_test, y_predicted = Y_pred, prob_predicted = prediction)

# ---
# CONFUSION MATRIX
@sk_import metrics: (accuracy_score, confusion_matrix)
accuracy_score(Y_test, Y_pred)
confusion_matrix(Y_test, Y_pred)

```

D先生 ： “まずは欠損値を覗いて、入力データのアンバランスを見てみましょう。”

![imageJL1-21-7](https://introJL1973.github.io/images/imageJL1-21-7.jpg)

QEU:FOUNDER ： “**0群と1群の入力データの数量差**が大きすぎます。多分、このままでは正しい情報（分析結果）を得るのは難しいでしょう。何はともあれ、先を急ごう・・・。分析結果をドン！！”

![imageJL1-21-8](https://introJL1973.github.io/images/imageJL1-21-8.jpg)

QEU:FOUNDER ： “あきらかに**統計のR言語**バリの分析結果です。すばらしい・・・。説明変数（X）の刈り取りは自分で工夫してください。次に、予測値と実際値を比較してみましょう。”

![imageJL1-21-9](https://introJL1973.github.io/images/imageJL1-21-9.jpg)

D先生 ： “今回は、リンク関数を変えて確率を出力しています。予測と実際が食い違う場合、確率が0.5あたりにあるわけじゃないんだ・・・。”

QEU:FOUNDER ： “ここら辺は本来はもうちょっと細かく検証しましょう。最後にメトリックスとCONFUSION_MATRIXを出力してみましょう。”

![imageJL1-21-10](https://introJL1973.github.io/images/imageJL1-21-10.jpg)

QEU:FOUNDER ： “メトリックスの計算時に警告が出ています。いろいろ原因を調べていますが、いまだに対策がわかりません。とりあえず、自分で調べてください。いやなら、メトリックスを手動で計算して、マクロを使わないでください。”

D先生 ： “混合マトリックスのPython版の結果とJulia版の結果は評価が微妙ですね。これは、ちょっとしたことで結果が変わりそうです。”

QEU:FOUNDER ： “だからロジスティック回帰はこわいんだ・・・。”




## ～　まとめ　～


QEU:FOUNDER ： “天才がこの言葉を語ると、しみじみとくるねぇ・・・。”

![imageJL1-21-11](https://introJL1973.github.io/images/imageJL1-21-11.jpg)

C部長 : “**「高齢者によるイノベーション」に応用**しなければいけないですね。”

QEU:FOUNDER ： “そうそう・・・。彼らは年金をもらえるんだから、べつに結果を急ぐ必要がないんだ・・・。普通は60歳になると嘱託になるんだったら、いっそ研究職になってしまえばいいんじゃないか？逆に言うと、自分な時間がない若年層の方がイノベーションに向かないんじゃないかと思っています。”

C部長 : “わけのわからないオッサンがマントラを1000回唱えるイノベーションを開発するかもしれませんが・・・（笑）。”

- おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
- オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」
- オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER ： “再度言います。そんなモン、意味なし。即時却下・・・(笑)。”

