## QEUR22_EXAMPLE05:　事例(5)～ 手書き数字の判別-Julia-Flux(SOART後半)

## ～　SOARTメトリックスの長所と弱点　～

D先生 （設定65歳）： “前回は、SOARTメトリックスについての簡単なレビューと、テクノメトリックスの生成プログラムを紹介しました。今回は、そのつづきです。・・・遅れましたが、、この番組は**「高齢者によるイノベーション」**です。「安いモノを作る」以外にも、我々オッサンには能があるのだ！”

<iframe width="560" height="315" src="https://www.youtube.com/embed/e8aiitAAAZY" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER （設定65歳） ： “もちろん！**売値が高くても売れるものを作る**。そうすれば、サプライチェーン全体が儲かると・・・。そうすれば、云々・・・。それでは、いきなりプログラムに行きましょう。”

![imageJL1-84-1](https://introJL1973.github.io/images/imageJL1-84-1.jpg)

D先生 ： “なんか、あらかじめ言うことはないんですか？”

QEU:FOUNDER ： “ないでしょう、さしあたり・・・。・・・ドン。”

```julia
# Flux-MNIST(SQART法適用モデル)
# 注意：　感度（回転）とSN比（距離）を考慮しています（合計４８次元）
# Simple Multi-layer Perceptron
using DataFrames, CSV
using Flux, Statistics
using Flux.Data: DataLoader
using Flux: onehotbatch, onecold, logitcrossentropy, throttle, @epochs, params
using Base.Iterators: repeated
using CUDA
#using MLDatasets
if has_cuda()        # Check if CUDA is available
    @info "CUDA is on"
    CUDA.allowscalar(false)
end
using Plots
ENV["COLUMNS"] = 1000
# ----
# Read the file using CSV.File and convert it to DataFrame
# ----
# train DB
dfbeta_train = DataFrame(CSV.File("outbeta_train.csv"))
dfsnr_train  = DataFrame(CSV.File("outsnr_train.csv"))
# DB内容の出力
#first(dfsnr_train,5) #displaying the first 5 rows to get an overview of the dataset
#describe(select(dfsnr_train, Not(:label)))
# ----
# test DB
dfbeta_test  = DataFrame(CSV.File("outbeta_test.csv"))
dfsnr_test   = DataFrame(CSV.File("outsnr_test.csv"))
# DB内容の出力
first(dfsnr_test,5) #displaying the first 5 rows to get an overview of the dataset
# ----
#describe(select(dfsnr_test, Not(:label)))

```

![imageJL1-84-2](https://introJL1973.github.io/images/imageJL1-84-2.jpg)

D先生 ： “ちょっと待った！！プログラムでは、Y1（感度）のデータも読み込んでいます。Y2(SN比、距離)だけでディープラーニング学習をするんじゃなかったんですか？”

QEU:FOUNDER ： “もう、すでに実験してみました。しかし、Y2メトリックスだけでは70％台の正確度しか出なかったです。そこで、しようがないのでY1メトリックスも付け加えました。”

D先生 ： “あともう一つ・・・、**値がゼロになっているレコード**がありますよね。”

QEU:FOUNDER ： “わははは・・・（笑）。それについては後で・・・。それでは、つづきをドン！！”

```julia
# ------
# パラメータ群
rate::Float64 = 1e-3    # learning rate
batchsize::Int = 2048   # batch size
epochs::Int = 10        # number of epochs
device::Function = gpu  # set as gpu, if gpu available

# ------
# Loading Dataset    
xtrain_snr = select(dfsnr_train, Not(:label))
ytrain_org = select(dfsnr_train, :label)
xtest_snr = select(dfsnr_test, Not(:label))
ytest_org = select(dfsnr_test, :label)

# Convert to matrix
xtrain_beta = convert(Array{Float32}, dfbeta_train)
xtrain_snr  = convert(Array{Float32}, xtrain_snr)
ytrain_org  = convert(Array{Int64}, ytrain_org)
xtest_beta  = convert(Array{Float32}, dfbeta_test)
xtest_snr   = convert(Array{Float32}, xtest_snr)
ytest_org   = convert(Array{Int64}, ytest_org)

# ------
# データの成形
xtrain = cat(xtrain_beta, xtrain_snr, dims=2)
xtest  = cat(xtest_beta, xtest_snr, dims=2)
ytrain_org = ytrain_org[:,1]
ytest_org  = ytest_org[:,1]

# One-hot-encode the labels
ytrain, ytest = onehotbatch(ytrain_org, 0:9), onehotbatch(ytest_org, 0:9)

# Batching
train_data = DataLoader((Matrix(xtrain'), ytrain), batchsize=batchsize, shuffle=true)
test_data = DataLoader((Matrix(xtest'), ytest), batchsize=batchsize)

# ------
# MAIN ROUTINE
# ------
function build_model()
    return Chain(
        Dense(48, 128, relu),
		Dense(128, 128, relu),
        Dense(128, 10))
end

# ------
function loss_all(dataloader, model)
    l = 0f0
    for (x,y) in dataloader
        l += logitcrossentropy(model(x), y)
    end
    l/length(dataloader)
end

# ------
function accuracy(data_loader, model)
    acc = 0
    for (x,y) in data_loader
        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))*1 / size(x,2)
    end
    acc/length(data_loader)
end

# ------
train_losses = []
test_losses  = []
train_acces  = []
test_acces   = []

# ------
# Construct model
m = build_model()
train_data = device.(train_data)
test_data = device.(test_data)
m = device(m)
loss(x,y) = logitcrossentropy(m(x), y)

## Training
callbacks = [
    () -> @show(loss_all(train_data, m))
    () -> push!(train_losses, loss_all(train_data, m))
    () -> push!(test_losses, loss_all(test_data, m))
    () -> push!(train_acces, accuracy(train_data, m))
    () -> push!(test_acces, accuracy(test_data, m))
]

opt = ADAM(rate)
# ------
@epochs epochs Flux.train!(loss, params(m), train_data, opt, cb = callbacks)

```

![imageJL1-84-3](https://introJL1973.github.io/images/imageJL1-84-3.jpg)

```julia
# ------
# Display Losses
x = range(1, length(train_losses))
plot(x, [train_losses,test_losses], title="Learning Curve - Loss trend", label=["Train" "Test"], linewidth=3)

```

![imageJL1-84-4](https://introJL1973.github.io/images/imageJL1-84-4.jpg)

```julia
# Display Accuracy
plot(x, [train_acces,test_acces], title="Learning Curve - Accuracy trend", label=["Train" "Test"], lin-ewidth=3)
println("train_acces[end]:", train_acces[end])
println("test_acces[end]:", test_acces[end])

```

![imageJL1-84-5](https://introJL1973.github.io/images/imageJL1-84-5.jpg)

```julia
# ------
# Display Confusion Matrix
cm = zeros(Int64, 10, 10)

for (x,y) in test_data
    pred_test_labels = onecold(cpu(m(x)))
    true_test_labels = onecold(cpu(y))
    #println("pred_test_labels:", pred_test_labels)
    #println("true_test_labels:", true_test_labels)
    # ---
    for i in 1:length(pred_test_labels)
        cm[pred_test_labels[i],true_test_labels[i]] += 1
    end
end

# ------
# Display raw data
cm

```

![imageJL1-84-6](https://introJL1973.github.io/images/imageJL1-84-6.jpg)

D先生 ： “う～ん、**48次元のインプットで正確度が85％**か・・・。まあ、「そんなもの」とはいえるが・・・。・・・でも、SOART法はPCAよりも計算の手間がかかるので、同レベルでは困ります。もう少し、なんとかならないでしょうか？”

QEU:FOUNDER ： “さっき、D先生が「データセットに0値を含むレコードがある」と指摘したでしょ？あれは、**「ABCD領域のいづれかで計算上の異常が起こっている」**ものです。そのレコードを外してやってみましょう。ひきつづいて追加試験をドン・・・。実際にはChain関数を少し変えたので、興味があれば自分で実験して検証してみてください。”

**(データベースの修正後の再実験の結果)**

**(判別精度)**

![imageJL1-84-7](https://introJL1973.github.io/images/imageJL1-84-7.jpg)

**(マトリックス)**

![imageJL1-84-8](https://introJL1973.github.io/images/imageJL1-84-8.jpg)

D先生 ： “かなり良い予測レベルに近づきました。やはり、0値（計算異常）が悪さをしていたのか・・・。”

QEU:FOUNDER ： “・・・というか、SOART法は汎用なメトリックスではなく、**計測対象が「型にはまればはまるほど良い」という特徴**を持っているんですよ。”

D先生 ： “そういう意味では、究極の「型にはまる」状況は外観自動検査になりますね。”

QEU:FOUNDER ： “だから、**SOART法は外観自動検査機のために考案した**んですよ。なにはともあれ、Julia紹介を目的とした、このシリーズは終了します。”

D先生 ： “次は、もっと面白くなります(笑)。”


## ～　まとめ　～

QEU:FOUNDER ： “さあ、とうとうC国が動き出しましたね・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/-Nc1euN8l9Y" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “とうとう、C国幣で重要資源を買える時代がくるんでしょうか・・・。”

QEU:FOUNDER ： “さぁてね・・・、**「超のつく」一大事**なので素直に実現するかねぇ・・・。”

![imageJL1-84-9](https://introJL1973.github.io/images/imageJL1-84-9.jpg)

QEU:FOUNDER ： “でもね・・・。サッカーのワールドカップが**中東で開催されたのも奇遇**ですね。”

C部長 : “しかも、**「番狂わせ」続出**という・・・。”

QEU:FOUNDER ： “なんでかな・・・？”
