## QEUR22_INTRO14:　MLJ(1) ～SVM（サポートベクトルマシン）

## ～　ああ・・・、「格が違う」人たち・・・　～

D先生 （設定65歳）： “ふわふわ、フワフワと・・・。MLJパッケージの中を散歩（道草）している、私たち **「高齢者によるJulia入門」** チームです。さて、アランチューリング研究所も開発に参与しているMLJは巨大です。我々の道草は、まさに今、「始まったばかり」・・・。”

![imageJL1-16-1](https://introJL1973.github.io/images/imageJL1-16-1.jpg)

QEU:FOUNDER （設定65歳） ： “ちょっとだけ道草の道草・・・、今回はC国のJulia言語に対する見方をお勉強しましょう。道草は、範囲が広いほどイケている・・・（笑）。それにしても、このエッセイはすごいです。基本はJuliaアゲの記事ではありますが、ちょっと面白いネタも含まれているので、あえて部分的に紹介します。このグラフ（↓）にはショックを受けたなァ・・・。”

![imageJL1-16-2](https://introJL1973.github.io/images/imageJL1-16-2.jpg)

D先生 ： “これはC国における主要都市別のJulia言語ユーザー数ですね。でも、この円グラフの何がショック？”

QEU:FOUNDER ： “そう・・・、**意外なことに杭州が一位じゃない**んだ・・・。C国において、情報科学系の学生が最も多い都市は杭州であるはず。つまり、C国のJulia熱はA国のように大学が牽引しているんじゃないということ・・・。”

D先生 ： “第一位は北京ですよね。・・・ということは。C国のJulia関連のブログ記事はそれなりに増えてはいますが、Pythonのように爆発はしていません。その理由がわかりました。おそらく、**想像以上のことが水面下で行われている**んでしょう。”

![imageJL1-16-3](https://introJL1973.github.io/images/imageJL1-16-3.jpg)

QEU:FOUNDER ： “最後に、この文章のまとめの言葉です。これに関しては能書きも何もいわない、よく文章を味わえ・・・。ドン・・・。”

最後に、哲学者ウィトゲンシュタインの『論理学哲学論考』の言葉を借りれば、「私の言語の限界は、私の世界の限界を意味する」のである。 プログラミング言語は単なる道具であり、あるプログラミング言語でできることは他のプログラミング言語でもできると考え、他のプログラミング言語を学び、使うことを拒否することがよくあります。 中国語を知らない人が儒教の思想を理解できないように、言語も深く学ばないと、その言語が表す人々の文化やその背景にある思想をより深く理解することはできないのです。 関数型プログラミング言語であるJuliaは、C/C++/Pythonのような主流の言語とは全く異なる考え方を採用しており、それを知り、使うようになると、常に何か余分なものを学び、得ることができるようになるのです。

D先生 ： “C国がA国に比肩しうるJulia大国になることは、すでに約束されています。ちなみに、この美しい文章については、他の誰かの引用の可能性もあることは、一応皆様に注意しておきます。まあ、その可能性は少ないとは思うが・・・。”

QEU:FOUNDER ： “もう負けまくりじゃん、J国・・・。それでは、気を取り直してMLJの道草を始めましょう。ほとんど同じサポートベクトルマシン（SVM）の解析事例で、PythonとJuliaを比較してみましょう。まずはコードから・・・。”

```python
# SVM in Python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

# Import the dataset using Seaborn library
iris=pd.read_csv('iris.csv')

# Creating a pairplot to visualize the similarities and especially difference between the species
sns.pairplot(data=iris, hue='Species', palette='Set2')

# Train Test Split
from sklearn.model_selection import train_test_split

# Separating the independent variables from dependent variables
x=iris.iloc[:,:-1]
y=iris.iloc[:,4]
x_train,x_test, y_train, y_test=train_test_split(x,y,test_size=0.30)

# Training and Fitting the model
from sklearn.svm import SVC
model=SVC()
model.fit(x_train, y_train)

# Predictions from the trained model
pred=model.predict(x_test)

# Importing the classification report and confusion matrix
from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test,pred))

```

D先生 ： “PythonによるSVCはもう何度もやっていますから・・・。”

![imageJL1-16-4](https://introJL1973.github.io/images/imageJL1-16-4.jpg)

QEU:FOUNDER ： “当たり前ながら、この方法(SVM)はイケているんですよ・・・。以上、比較のための例でした。”

![imageJL1-16-5](https://introJL1973.github.io/images/imageJL1-16-5.jpg)

D先生 ： “次は、**Julia言語でSVMをやってみましょう**。参考資料は以下の通り。ただし、いままでの経験を使って改造しています。”

![imageJL1-16-6](https://introJL1973.github.io/images/imageJL1-16-6.jpg)

QEU:FOUNDER ： “今回も同様に、プログラムをドン！”

```julia
#=
  SVCによるIRIS予測(JULIA入門)
=#
using CSV, DataFrames
using MLJ
using PrettyPrinting
using Random

# Separate Fisher's Iris dataset features and labels
iris = CSV.read("iris.csv", DataFrame)    # also see "adult" and "digits" datasets

# SepalLength,SepalWidth,PetalLength,PetalWidth,Species
X = Matrix(iris[!,["SepalLength","SepalWidth","PetalLength","PetalWidth"]])
y = convert(Array, iris[!,"Species"])

# -----
# change stringth into integer
n   = length(y)
y_num = Array{Int}(undef,n)
for i in 1:length(y)
	if occursin("setosa",y[i])
		y_num[i] = 1
	end
	if occursin("versicolor",y[i])
		y_num[i] = 2
	end	
	if occursin("virginica",y[i])
		y_num[i] = 3
	end	
end
y_num

# -----
# Split database as train and test
function partitionTrainTest(X, y, at = 0.7)
    n = size(X, 1)
    idx = shuffle(1:n)
    train_idx = view(idx, 1:floor(Int, at*n))
    test_idx = view(idx, (floor(Int, at*n)+1):n)
    return X[train_idx,:], X[test_idx,:], y[train_idx], y[test_idx]
end

# Split databasr into test-train
xtrain,xtest,ytrain,ytest = partitionTrainTest(X, y_num, 0.7) # 70% train-30% test
xtest

# Variable conversion(train)
X = MLJ.table(xtrain)
y = categorical(ytrain)

# Support Vector Machine for Classification
SVC = @load SVC pkg=LIBSVM
svc_mdl = SVC()
svc = machine(svc_mdl, X, y)
fit!(svc)

# Variable conversion(test)
X2 = MLJ.table(xtest)
ypred = MLJ.predict(svc, X2)
y2 = Array{Int}(ypred)

# -----
dim = 3
# confusion matrix calculation in Julia
function confusionmatrix(predictions, labels, dim)
   c = zeros(dim, dim)
   for i in 1:length(labels)
       c[labels[i] ,predictions[i]] += 1 
   end 
   return c
end

c = confusionmatrix(y2, ytest, dim)
display(c)

```

D先生 ： “見慣れない命令文がついてきました・・・。”

![imageJL1-16-7](https://introJL1973.github.io/images/imageJL1-16-7.jpg)

QEU:FOUNDER ： “う～ん・・・。**Julia 言語って面倒臭い**と正直思いました。ターゲットであるyにおいて、**SVM(分類)に使う型は「カテゴリカル」であることを宣言する**必要があるようです。この宣言をしないとエラーが出ます。”

D先生 ： “あとは、確かに決定木のときと変わらないですね・・・。”

![imageJL1-16-8](https://introJL1973.github.io/images/imageJL1-16-8.jpg)

QEU:FOUNDER ： “pythonとjulia言語の判別性能については言わないです。どうせ、大して変わらない・・・。今回はここまでです。”

D先生 ： “次は何かな・・・？”


## ～　まとめ　～

QEU:FOUNDER ： “あ～あ・・・。Y先生に言われちゃった。もう **「手詰まり」**だって・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/0gd24YZ7J6s" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “MMTってだめなのですか？FOUNDERはMMT‘erでしょ？”

QEU:FOUNDER ： “MMTという考え方は　**「今でもアリ」**　だと思っています。ただし、**今のJ国はMMT適用外です。「生産力が全然足らない」と思います**。いやいや、こういう結末になるとは・・・。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

### オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

C部長 : “じゃあ、**「オッサン」に生産力を復興させてもらい**ましょう。やってくれるでしょう。多分・・・。”

QEU:FOUNDER ： “我々は別路線で・・・(笑)。”


