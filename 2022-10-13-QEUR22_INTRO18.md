## QEUR22_INTRO18:　Julia事例(8)～K平均法

## ～　やっぱり、少し違うんだネ　～

D先生 （設定65歳）： “さて、さらに事例研究がつづきます。この番組は「高齢者によるJulia言語入門」です・・・。ちょっとKmean法の記事を見つけたので、ネタとして取り上げていいですか？インド系？なのかな？若い女性の記事で好感が持てます。”

![imageJL1-19-1](https://introJL1973.github.io/images/imageJL1-19-1.jpg)

QEU:FOUNDER （設定65歳） ： “Julia言語関連であれば何でもいいです。**「富士山はいきなり高いんじゃなくて、裾野が広いから高いんだよね」**・・・。少なくともJ国において、現在のJulia言語の状況は絶対的なWeb情報不足です。内容の良しあしを問うレベルじゃないです。”

![imageJL1-19-2](https://introJL1973.github.io/images/imageJL1-19-2.jpg)

D先生 ： “何がなんでもネタが欲しい段階・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/yF7q2UvLqSo" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “Julia言語をより良いモノに改造するのは「エリートさん（開発者）」たちの仕事なんですが、それがより良いモノになるには、「それを使う一般の人たち（ユーザー）」がいて初めてやれることです。「立派なエリートさえいれば世の中は何とかなるんだ」という考え方は間違いです。2000年代はそういう誤解が蔓延した・・・。どんなに立派なエリートでもね、自分だけではなんともならない・・・。”

![imageJL1-19-3](https://introJL1973.github.io/images/imageJL1-19-3.jpg)

D先生 ： “そうですね**「お前の代わりはいくらでもいる。人間を上下に分離し、上（エリート）がいれば何とかなる」**って昔、はやったなァ・・・。ちなみにエリートって、画像の右側？それとも左側？”

QEU:FOUNDER ： “えっ！？なにを言っているんですか！？**左側**に決まっているじゃないですか！！！”

D先生 ： “そう・・・、そうですよね。気を取り直して、K平均法の話に戻りましょう。Pythonに関しては私から紹介します。元のプログラムから変わっていますよ。”

```python
 # python- clustering(Template)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('clustering.csv')
data.head()

data = data.loc[:, ['ApplicantIncome', 'LoanAmount']]
data.head(2)

# Convert to numpy array
X = data.values

# Visualize the data points
sns.scatterplot(x=X[:,0], y=X[:, 1])
plt.xlabel('Income')
plt.ylabel('Loan')
plt.show()

# SKLearnによる改造版
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

cost_list = []
for k in range(1, 10):  
    model = KMeans(n_clusters=k, random_state=0, init='random')  # initを省略すると、k-means++法が適応される(randomではk-means法が適応)
    model.fit(X)
    clusters = model.predict(X)  # データが属するクラスターのラベルを取得
    # model.cluster_centers_ でクラスター重心の座標を取得できる
    centroids = model.cluster_centers_
    # WCSS (Within cluster sum of square)    
    cost = calculate_cost(X, centroids, clusters)    
    cost_list.append(cost)

# Plot a line plot between WCSS and k
# WCSS doesn’t reduces much after k=4, so make 4 clusters
sns.lineplot(x=range(1,10), y=cost_list, marker='o')
plt.xlabel('k')
plt.ylabel('WCSS')
plt.show()

# Make clusters
k = 4
#centroids, cluster = kmeans(X, k)
model = KMeans(n_clusters=k, random_state=0, init='random')  # initを省略すると、k-means++法が適応される(randomではk-means法が適応)
model.fit(X)
clusters = model.predict(X)  # データが属するクラスターのラベルを取得
# model.cluster_centers_ でクラスター重心の座標を取得できる
centroids = model.cluster_centers_

# Visualize the clusters formed
sns.scatterplot(x=X[:,0], y=X[:, 1], hue=clusters)
sns.scatterplot(x=centroids[:,0], y=centroids[:, 1], s=100, color='y')
plt.xlabel('Income')
plt.ylabel('Loan')
plt.show()

```

QEU:FOUNDER ： “なんだ！？オリジナルから変わった部分はskLearnからK平均法のモジュールを取ってきたことだけかね・・・。ま、いいや・・・。まずは読み込んだCSVデータを見てみましょう。UCIのデータセットであるかどうかは不明だが、ローン関係のモノらしいです。”

![imageJL1-19-4](https://introJL1973.github.io/images/imageJL1-19-4.jpg)

D先生 ： “このうち、2つの変数だけを使ってクラスタ分析をしたようです。エルボー法によるクラスタ数の最適化を説明するために・・・。”

![imageJL1-19-5](https://introJL1973.github.io/images/imageJL1-19-5.jpg)

QEU:FOUNDER ： “へえ・・・、**「エルボー（ひじ）」**っていうのか。知らんかった・・・（笑）。クラスタ数４のあたりが最適になるようです。最適なクラスタ数の状態を散布図で確認しましょう。”

![imageJL1-19-6](https://introJL1973.github.io/images/imageJL1-19-6.jpg)

QEU:FOUNDER ： “これはわかりやすい事例ですね。それでは、これをJulia(言語)でやってみましょう。それでは、Julia版のプログラムをドン・・・。”

```julia
#=
   ハイパフォーマンス言語JULIAをやってみる
   K平均法
=#
using CSV, DataFrames, ScikitLearn, PyPlot, Clustering, Plots
raw_data = CSV.read("clustering.csv", DataFrame)


# Pick up only 2 variables
X = Matrix(raw_data[!, [:ApplicantIncome, :LoanAmount]])

# Fetching the each value of data 
# using collect() function and 
# storing in features
features = collect(X)'

# using Clustering
# running  K-means for the 4 clusters
result = kmeans(features, 4)

# Centoroid vector
centroids = result.centers

# counts of clusters
counts = result.counts

# Centoroid vector
clusters = result.assignments

# plot with the point color mapped 
# to the assigned cluster index
# using Plots
Plots.scatter(raw_data.ApplicantIncome, raw_data.LoanAmount
	, group=result.assignments, legend=true
	, title="cluster analysis: k=4", titlefontsize=16)

# Calculate WCSS
function calculate_cost(X, centroids, clusters, row_data)
    sum = 0  
    for i in 1:row_data
		val_0 = X[i,1]
		val_1 = X[i,2]
        #print(centroids[clusters[i], 1])
        sum += sqrt((centroids[1,clusters[i]]-val_0)^2 +(centroids[2,clusters[i]]-val_1)^2)
	end
    return sum
end

# Find K value using elbow method
cost_list = Float64[] # => 0-element Float64 Array
XT  = transpose(features)
row_data, col_data = size(XT)
#----
for knum in 1:10    
    result = kmeans(features, knum)
    #----
    # Centoroid vector
    centroids = result.centers
    # Cluster vector
    clusters = result.assignments
    #----
    # WCSS (Within cluster sum of square)    
    cost = calculate_cost(XT, centroids, clusters, row_data)    
    #println(cost)
	push!(cost_list,cost) 
end
println(cost_list)

# plot graph for finding elbow
Plots.plot(cost_list, xlabel="number of cluster", ylabel="cost" )

```

QEU:FOUNDER ： “Julia言語の場合、解析エンジンにデータセットをインプットするときに、なぜか**「転置（マトリックス）」**になるんですよね。”

![imageJL1-19-7](https://introJL1973.github.io/images/imageJL1-19-7.jpg)

QEU:FOUNDER ： “さらに、解析エンジンのアウトプットの出力方法が少し違うんですよね。個人的にはこのやり方のほうが好き。ここら辺は慣れの問題だけだが・・・。”

![imageJL1-19-8](https://introJL1973.github.io/images/imageJL1-19-8.jpg)

D先生 ： “散布図も覗いてみましょうか・・・。Pythonと同じ結果だけど・・・（笑）。”

![imageJL1-19-9](https://introJL1973.github.io/images/imageJL1-19-9.jpg)

QEU:FOUNDER ： “もっとも面倒だったのが、エルボー法のためにコストを求める関数の設計です。Pythonのモノを流用したつもりだが、Julia版は入力データ（X）が転置されているので様子が変わるんです。これもJulia言語に慣れれば大したことがないかもね。最後のアウトプットとして、エルボー曲線を見てみましょう。”

![imageJL1-19-10](https://introJL1973.github.io/images/imageJL1-19-10.jpg)

D先生 ： “まあ、これで概要は分かってきました。”

QEU:FOUNDER ： “どんどん他の手法も紹介していきましょう。”


## ～　まとめ　～

QEU:FOUNDER ： “ずいぶん高くなった。ラズパイって、そんなに人気があるのかなぁ・・・？”

![imageJL1-19-11](https://introJL1973.github.io/images/imageJL1-19-11.jpg)

C部長 : “価格高騰の原因は半導体不足とは言われています。それでも、それなりの需要がないと、こうはならないわけで・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/WU7mVmzJfaI" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “ブラジルの若者が立ち上げた**OpenPLCプロジェクト**もかなり有名になってきており、これをラズパイに組み込んで、産業用途に使うようになったのかな？”

![imageJL1-19-12](https://introJL1973.github.io/images/imageJL1-19-12.jpg)

C部長 : “それはわかりません。ただし、**OpenPLCがペーパーの本になったこと**は、普及のための重要な一歩にはなります。・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/gTVzd23Ej0o" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “C部長の会社で、カクテル・メイカーを作ってくれないですか？ただ単に、自分がおいしいお酒を飲みたいだけですが・・・(笑)。”

C部長 : “PLCってマニュアル操作のためコントローラですが、せっかく作るんだったらおいしいお酒を作れるように「学習できるｼﾛﾓﾉ」が欲しいですね。”

QEU:FOUNDER ： “そういう話になっちゃうとPLCを使う意味がなくなります。そういう意味では将来的に「PLCって本当に必要かな？」とも思うし・・・。”

