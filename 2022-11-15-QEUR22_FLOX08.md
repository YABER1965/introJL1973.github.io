## QEUR22_FLUX07:　ディープラーニング(4)～回帰-Flux-Julia

## ～　Fluxって、か～んたん・・・　～

D先生 （設定65歳）： “Fluxの紹介はこれが最後か・・・。ちなみに、この番組は**「高齢者によるイノベーション」**です。オレたちはすごいだゾ。ガオー！”

![imageJL1-68-1](https://introJL1973.github.io/images/imageJL1-68-1.jpg)

QEU:FOUNDER （設定65歳） ： “〇されることは、「たぶんない」らしいです・・・(笑)。それでは、今回はFluxオンリーで当てはめをやってみようということです。今回の先生はコレ・・・（↓）。”

![imageJL1-68-2](https://introJL1973.github.io/images/imageJL1-68-2.jpg)

D先生 ： “実際には。参考ブログは他にもたくさんあるでしょ？”

QEU:FOUNDER ： “もちろん・・・。「学習する機能が関数になっているのがいいかな？」って、アドバンテージはそれくらい・・・。あろ、Chain関数も外部から切換できるようになっています。”

D先生 ： “ほう・・・。”

QEU:FOUNDER ： “ひとつのChain関数は失敗しているけどね・・・（笑）。でもね、それは敢て残しているんです。ユーザーが自分で改造して使えるように・・・。それではプログラムをドン・・・。”

```julia
# Julia - simplified Flux regression
# (失敗もあるよ)
using DataFrames, CSV
using Plots
using Flux
using Statistics

ENV["COLUMNS"] = 1000
# ----
# Read the file using CSV.File and convert it to DataFrame
df = DataFrame(CSV.File("auto-mpg-processed-data.csv"))
first(df,5) #displaying the first 5 rows to get an overview of the dataset

```

![imageJL1-68-3](https://introJL1973.github.io/images/imageJL1-68-3.jpg)

```julia
# 統計分析(ONEHOTをのぞく)
describe(select(df, Not([:USA,:Europe,:Japan])))

```

![imageJL1-68-4](https://introJL1973.github.io/images/imageJL1-68-4.jpg)

```julia
# ----
# 散布図を作画する[:USA,:Europe,:Japan]
df_us  = df[df.USA.==1,:]
df_eu  = df[df.Europe.==1,:]
df_ja  = df[df.Japan.==1,:]
# ---
# 車の馬力
scatter(title="Horsepower vs MPG", xlabel = "Horsepower", ylabel="MPG",
             df_us.Horsepower, df.MPG, color="blue", label="USA")
scatter!(df_eu.Horsepower, df.MPG, color="red", label="Europe")
scatter!(df_ja.Horsepower, df.MPG, color="green", label="Japan")

```

![imageJL1-68-5](https://introJL1973.github.io/images/imageJL1-68-5.jpg)

```julia
# ---
# 車の重さ
scatter(title="Weight vs MPG", xlabel = "Weight", ylabel="MPG",
             df_us.Weight, df.MPG, color="blue", label="USA")
scatter!(df_eu.Weight, df.MPG, color="red", label="Europe")
scatter!(df_ja.Weight, df.MPG, color="green", label="Japan")

# ----
# X(Matrix)とy(Array)を抽出する
y = df[!, :MPG]; #Y-values
X = select(df, Not(:MPG)); #features
target = convert(Array, y)
matrix_train = convert(Matrix, X)

# ----
# defining function to scale features
using Statistics

function scale_features(X)
    μ = mean(X, dims=1)
    σ = std(X, dims=1)
    # ---
    X_norm = (X .- μ) ./ σ
    return (X_norm, μ, σ)
end
 
#defining function to transform features.
#function transform_features(X, μ, σ)
#    X_norm = (X .- μ) ./ σ
#    return X_norm
#end
 
# Scale training features
matrix_train_scaled, μ, σ = scale_features(matrix_train)
matrix_train_scaled

# Transform the testing features
#matrix_test_scaled = transform_features(matrix_test, μ, σ)
#print("Training and testing data are now transformed")

```

![imageJL1-68-6](https://introJL1973.github.io/images/imageJL1-68-6.jpg)

```julia
# ---
# 簡易型機械学習システム
function train_model(x, y, dim_in=1, hl_neurons=0)
    
    # x must be an `in` × N matrix
    x = x'
    
    # Create data iterator for 5000 epochs
    data_iterator = Iterators.repeated((x, y), 5000)
    
    # Set-up model layout
    if hl_neurons==0
        m = Chain(Dense(dim_in,1), identity)
    else
        m = Chain(Dense(dim_in, hl_neurons, relu),
                  Dense(hl_neurons, 1, identity))
    end
    
    #Our loss function to minimize
    loss(x, y) = Flux.mse(m(x), y')
    optimizer = Flux.ADAM(0.001)
    Flux.train!(loss, Flux.params(m), data_iterator, optimizer)
    return m
end
# ---
# 線形予測(neuronを0とした場合)
model=train_model(matrix_train_scaled, target, 9, 0)

y_linear=reshape(model(matrix_train_scaled'), length(target),)

```

![imageJL1-68-7](https://introJL1973.github.io/images/imageJL1-68-7.jpg)

```julia
# ----
# データの追加(linear)
arr_columns = [:Cylinders,:Displacement,:Horsepower,:Weight,:Acceleration,:Model_Year,:USA,:Europe,:Japan]
dfp	 = DataFrame(matrix_train, arr_columns)
dfp.MPG = target
dfp.linear = y_linear
dfp

```

![imageJL1-68-8](https://introJL1973.github.io/images/imageJL1-68-8.jpg)

D先生 ： “予測結果が全然あっていないじゃないですか・・・。”

QEU:FOUNDER ： “参考ブログではax+bの形の予測なので「Dense(1,1)」のChain関数で予測ができたんです。もし、重回帰の場合には予測ができなくなるんですね。隠れ層は絶対に必要という教訓を得て、次に進みましょう。”

```julia
# ---
# 隠れ層のneuronを20とした場合
model=train_model(matrix_train_scaled, target, 9, 20)
y_hid=reshape(model(matrix_train_scaled'), length(target),)

# ---
# データの追加(hidden)
dfp.hidden = y_hid
dfp

```

![imageJL1-68-9](https://introJL1973.github.io/images/imageJL1-68-9.jpg)

```julia
# ---
# 当てはめの精度をグラフ化する
dfp_us  = dfp[dfp.USA.==1,:]
dfp_eu  = dfp[dfp.Europe.==1,:]
dfp_ja  = dfp[dfp.Japan.==1,:]
# ---
# 予測と実際の比較
Plots.scatter(title="Prediction vs Actual(hidden)", xlabel = "Prediction", ylabel="Actual",
             dfp_us.hidden, dfp.MPG, color="blue", label="USA")
Plots.scatter!(dfp_eu.hidden, dfp.MPG, color="red", label="Europe")
Plots.scatter!(dfp_ja.hidden, dfp.MPG, color="green", label="Japan")

```

![imageJL1-68-10](https://introJL1973.github.io/images/imageJL1-68-10.jpg)

D先生 ： “説明変数が十分なのかの議論はありますが、思ったよりも当てはめがよくないですね。”

QEU:FOUNDER ： “このブログでは、当てはめ精度について云々いわないから・・・。**「～やってみた」まで**です。”

D先生 ： “当てはめ精度を変えるのであれば、活性化関数を変えるとか、ノード数を変えるとか・・・。”

QEU:FOUNDER ： “隠れ数を１つだけ増やしてみましょうか？”

![imageJL1-68-11](https://introJL1973.github.io/images/imageJL1-68-11.jpg)

QEU:FOUNDER ： “少しだけ良くなったかね・・・。”

D先生 ： “これでFluxの説明については完結です。でも、もしこれ以上当てはめを良くしたいとすると、FOUNDERならどうします？”

QEU:FOUNDER ： “敢て手間をかけていいのであれば、TTTNN（T法2を使ったディープラーニング回帰）をやるね。この手法はすでに説明しています。その概要を言えば、D先生・・・。USAのプロットに注目してください。どんな感じですか？”

D先生 ： “USA群だけを見れば、かなり当てはめはいいように感じますが・・・。”

QEU:FOUNDER ： “そのUSA群のデータだけを使ってT法で回帰します。その回帰の残差を出力(Y)として、ディープラーニングで回帰させます。その2種の出力を合わせれば、もっと回帰が合うように思いますよ。”

D先生 ： “興味があるひとはやってみてください。・・・で、この次は何をします？”

QEU:FOUNDER ： “応用編かな？Julia言語の紹介はつづきます。”


## ～　まとめ　～

QEU:FOUNDER ： “あ～あ・・・、ほんとうに重い話だったね・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/RxfwZogY5Jk" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “FOUNDERは、「あの世代」の人たちを知っていますか？”

QEU:FOUNDER ： “「あの国」で働いたとき、現地採用として結構来ていました。部長とか顧問をやっているオッサン共は「若い奴らは仕事ができねえ・・・」とぼやいてましたがね。そりゃあ当たり前だろうに、経験が違うんだから・・・。でも・・・、思えば・・・。彼らはあの世代で「エリート」だったんだなぁ・・・。”

C部長 : “彼ら、楽しく仕事をしてましたか？”

QEU:FOUNDER ： “結構つらいよ・・・。オッサンはローカルを偏愛する傾向があるから・・・。女の子でも紹介されたんかなぁ・・・。”

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

C部長 : “オッサンって、基本が**「こんなアタマ（↑）」でできてる**から・・・。”

QEU:FOUNDER ： “小生は、それを鑑みてQEUシステムを立ち上げたわけ・・・。考えてみれば、ちょっと遅きに失するのだが・・・。小生のわかる品質の範囲に基づき・・・。”

![imageJL1-68-12](https://introJL1973.github.io/images/imageJL1-68-12.jpg)

C部長 : “QEUシステムの「この方針（↑）」はすでに変わっているんですが、**「理念」は生きています**ね・・・。”

QEU:FOUNDER ： “変わった理由・・・。もう**「品質」って意味ない**よね・・・。品質の定義を変えて、もう一度やり直す時期だと思います。”

C部長 : “どう変えるの？”

QEU:FOUNDER ： “それは次回に・・・。”

