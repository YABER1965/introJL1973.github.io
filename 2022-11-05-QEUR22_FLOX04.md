## QEUR22_FLUX04:　ディープラーニング(2A)～分類-Juliaの場合 (with iris)

## ～　実をいうと「まだ道半ばデス」・・・　～

D先生 （設定65歳）： “この番組は**「高齢者によるイノベーション」**です。いい年したオッサンがAIを操る21世紀・・・。これはユートピア？それとも「ディストピア」から・・・。”

![imageJL1-64-1](https://introJL1973.github.io/images/imageJL1-64-1.jpg)

QEU:FOUNDER （設定65歳） ： “**「ある種のオッサンたち」が暴れまわった、「ポスト平成」の後始末の現実**ですよ・・・。そういう意味で、我々不適切とは知りつつも、我が頭と体が動く範囲内で淡々と・・・（笑）。今回は、前回のディープラーニングで分類問題を解く件の第2回目です。Julia言語のディープラーニングで分類問題を解いてみましょう。Pythonと同様に、Julia言語もディープラーニングを使うためには多くの手段があります。その中でも、今回はコレ（↓）をつかいます。”

![imageJL1-64-2](https://introJL1973.github.io/images/imageJL1-64-2.jpg)

D先生 ： “MLJは、あの**「アランチューリング研究所」が開発している機械学習用のラッパー**ですよね。重回帰分析から決定木まで、ほとんどの手法を同じやり方で運用できるという・・・。”

![imageJL1-64-3](https://introJL1973.github.io/images/imageJL1-64-3.jpg)

QEU:FOUNDER ： “つまり、ディープラーニングも同様に、分類問題も回帰問題も同じ手順で解けるようになっています。それができるのは、**MLJのシステムがデータ・タイプを指定しているから**です。それでは、プログラムをドン・・・。今回もプログラムに実行結果を併記しています。”

```julia
# -------
# # Using MLJ with Flux to train the iris dataset
using MLJFlux
using MLJ
using Flux
using RDatasets
#using CSV
#import DataFrames: DataFrame, select, Not, describe, groupby
using Random
Random.seed!(123)
MLJ.color_off()

# ## Loading some data and instantiating a model
iris = RDatasets.dataset("datasets", "iris")

```

![imageJL1-64-4](https://introJL1973.github.io/images/imageJL1-64-4.jpg)

```julia
# ----
y, X = unpack(iris, ==(:Species), colname -> true, rng=123)
first(X, 5) |> MLJ.pretty

```

![imageJL1-64-5](https://introJL1973.github.io/images/imageJL1-64-5.jpg)

```julia
# -----
mutable struct MyNetworkBuilder <: MLJFlux.Builder
    n1::Int #Number of cells in the first hidden layer
    n2::Int #Number of cells in the second hidden layer
end

function MLJFlux.build(model::MyNetworkBuilder, n_in, n_out)
    layer1 = Flux.Dense(n_in, model.n1)
    layer2 = Flux.Dense(model.n1, model.n2)
    layer3 = Flux.Dense(model.n2, n_out)
    return Flux.Chain(layer1, layer2, layer3)
end

myClassifier = MyNetworkBuilder(8, 4)
nnClassifier = MLJFlux.NeuralNetworkClassifier(builder=myClassifier, batch_size=5, epochs=20)
mach = MLJ.machine(nnClassifier, X, y)
MLJ.fit!(mach, verbosity=3)

```

![imageJL1-64-6](https://introJL1973.github.io/images/imageJL1-64-6.jpg)

```julia
# -----
preds = MLJ.predict_mode(mach, X)
print(preds[1:5])

```

![imageJL1-64-7](https://introJL1973.github.io/images/imageJL1-64-7.jpg)

```julia
# -----
# ##  performance evaluation
r = range(nnClassifier, :epochs, lower=1, upper=200, scale=:log10)
curve = learning_curve(nnClassifier, X, y,
                       range=r,
                       resampling=Holdout(fraction_train=0.7),
                       measure=cross_entropy)


```

![imageJL1-64-8](https://introJL1973.github.io/images/imageJL1-64-8.jpg)

```julia
# ----
using PyPlot
figure(figsize=(10, 5))
PyPlot.plot(curve.measurements)
xlabel("Iteration")
ylabel("Cross Entropy")
PyPlot.title("Learning Curve")
grid("on")

```

![imageJL1-64-9](https://introJL1973.github.io/images/imageJL1-64-9.jpg)

D先生 ： “学習を終えたのちに**学習曲線（Learning Curve）**を改めて実施していますね。”

QEU:FOUNDER ： “予測のための学習（本学習）とハイパーパラメタを求めるための学習（予備学習）を分離するのは合理的だと思います。本来ならば、学習手順は学習曲線を求めた後で本学習をすべきだったんです。あと、学習曲線では損失のスケールをlog10にしていますが、別のやり方でもいいです。削ったら「デフォルト設定」になるだろうし・・・。”

D先生 ： “これは「そもそもの話」なんですが・・・。なんで、今回はいきなりIRISデータセットを使っているじゃないですか・・・。これは分類問題でもマルチクラス問題です。”

QEU:FOUNDER ： “初めは**バイナリ・クラス問題**のBreast_Cancerデータセットを使っていたのだが、うまく行っていないんです。多分、データ型の処理の問題で引っかかっているんじゃないかと思います。是非、各位がご自分でやってみてください。かくなる我々、うまくいったら随時アップしますので・・・。”


## ～　まとめ　～

### ・・・　前回のつづきです　・・・

C部長 : “えーっつ！？これが、あの団体のいう**「家庭」の由来**！？”

![imageJL1-64-10](https://introJL1973.github.io/images/imageJL1-64-10.jpg)

QEU:FOUNDER ： “さらにコレ（↓）・・・。”

![imageJL1-64-11](https://introJL1973.github.io/images/imageJL1-64-11.jpg)

C部長 : “あの儀式と教義との整合性がとれていますね。”

QEU:FOUNDER ： “個人の否定（堕落）・・・。一般概念としての家庭の否定（堕落）・・・。こういうことを理解したうえで議論しないと・・・。”

C部長 : “もうちょっと、A国もシビアになってもよさそうですが・・・。”

QEU:FOUNDER ： “それが、そうでもないんでよねえ・・・。記事によれば、**いいようにやられている**と思うんだが・・・。”

![imageJL1-64-12](https://introJL1973.github.io/images/imageJL1-64-12.jpg)

C部長 : “・・・と、・・・思うんだが？”

QEU:FOUNDER ： “コレ（↓）ではねぇ・・・。”

![imageJL1-64-13](https://introJL1973.github.io/images/imageJL1-64-13.jpg)

C部長 : “どこも、いっしょだねぇ・・・。”

QEU:FOUNDER ： “これが、一番の問題じゃないのか？”


